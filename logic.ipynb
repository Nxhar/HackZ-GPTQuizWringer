{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from APIKey import OPENAI_KEY \n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up Path for Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual Logic for processing an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImage(image):\n",
    "    image = Image.open('adobeTest.png')\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre defined requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextSplitter - predefined\n",
    "text_splitter = CharacterTextSplitter(\n",
    "separator = \"\\n\",\n",
    "chunk_size = 1000,\n",
    "chunk_overlap = 200,\n",
    "length_function = len\n",
    ")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key='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')\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coding the process that retrieves questions on a CORPUS of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENAI text compiler\n",
    "def getQuestions(text):\n",
    "\n",
    "    chunks = text_splitter.split_text(text)\n",
    "\n",
    "    vectorstore = FAISS.from_texts(texts = chunks , embedding = embeddings)\n",
    "\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(temperature=0, model='gpt-4',openai_api_key='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'),\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        memory=memory\n",
    "    )\n",
    "\n",
    "    query = '''You are an AI assistant that provides a set of 5 questions on the text given to you. \n",
    "    The difficulty level of each question varies, with the first question being easy, the second question being a medium difficulty, the third question being a hard difficulty, the fourth question being a harder difficulty and the fifth question being the hardest difficulty.\n",
    "    You have to generate questions in the format: \n",
    "     -- ['QUESTION1', 'QUESTION2', 'QUESTION3', 'QUESTION4', 'QUESTION5'] --\n",
    "     Please generate questions relevant to the provided text only, in increasing difficulty. Make sure the questions are comma seperated. \n",
    "       '''\n",
    "    \n",
    "    result = conversation_chain({'question':query})\n",
    "\n",
    "    return eval(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing question retrieval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is the role of chatbots in customer support?', 'What are some of the tasks involved in Natural Language Understanding?', 'What are some of the challenges faced by Natural Language Processing?', 'How does sentiment analysis contribute to understanding public opinion and sentiment?', 'Discuss the impact of advancements in NLP techniques on the accuracy and application of machine translation.']\n"
     ]
    }
   ],
   "source": [
    "sometext = '''\n",
    "Natural language processing (NLP) is a field of artificial intelligence (AI) that focuses on the interaction between humans and computers through natural language. It encompasses a wide range of tasks, including text analysis, machine translation, sentiment analysis, and chatbot development.\n",
    "Sentiment analysis, also known as opinion mining, is the process of determining the sentiment or emotion expressed in a piece of text. It can be used to analyze social media posts, customer reviews, and news articles to understand public opinion and sentiment.\n",
    "Machine translation is the automatic translation of text from one language to another using computational methods. With the advancement of NLP techniques, machine translation has become more accurate and widely used in applications like Google Translate.\n",
    "Chatbots are AI-powered conversational agents that can interact with users in a human-like manner. They are used in customer support, virtual assistants, and automated messaging systems.\n",
    "Text classification is the process of categorizing text documents into predefined classes or categories. It is often used in spam email detection, sentiment analysis, and content recommendation systems.\n",
    "Natural language understanding (NLU) is a subfield of NLP that focuses on the comprehension of human language by computers. NLU involves tasks like named entity recognition, semantic parsing, and question answering.\n",
    "Despite significant progress, NLP still faces challenges such as handling ambiguity, understanding context, and achieving human-level language understanding. Ongoing research aims to address these challenges.\n",
    "In conclusion, natural language processing plays a crucial role in modern AI applications. It enables computers to understand and generate human language, opening up opportunities for automation and improved human-computer interaction.\n",
    "\n",
    "'''\n",
    "\n",
    "questions = getQuestions(sometext)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What are chatbots used for?', 'What is the main purpose of sentiment analysis?', \"Can you explain what is meant by 'text classification' and give an example of its usage?\", 'What are some of the challenges faced by natural language processing?', 'Can you discuss the implications of advancements in natural language processing for modern AI applications and human-computer interaction?']\n"
     ]
    }
   ],
   "source": [
    "questions = eval(questions)\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual Backend.\n",
    "\n",
    "Backend --> 3 parts, \n",
    "1. Upload pure text\n",
    "2. Upload an Image to be converted to text\n",
    "3. Process that text and return a bunch of questions.\n",
    "\n",
    "Based on these questions, the user will return some answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [07/Oct/2023 18:28:15] \"OPTIONS /uploadText HTTP/1.1\" 200 -\n",
      "[2023-10-07 18:28:33,321] ERROR in app: Exception on /uploadText [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Nihar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 1455, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Nihar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 869, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Nihar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask_cors\\extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Nihar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 867, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Nihar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 852, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Nihar\\AppData\\Local\\Temp\\ipykernel_5344\\4288486881.py\", line 97, in uploadText\n",
      "    arrayOfQuestions  =  getQuestions(text)\n",
      "                         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Nihar\\AppData\\Local\\Temp\\ipykernel_5344\\4288486881.py\", line 38, in getQuestions\n",
      "    return eval(result['answer'])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<string>\", line 1\n",
      "    As an AI, I can generate questions based on a given text. However, I'm unable to determine the difficulty level of each question as it can be subjective and depends on the individual's knowledge and understanding of the topic.\n",
      "       ^^\n",
      "SyntaxError: invalid syntax\n",
      "127.0.0.1 - - [07/Oct/2023 18:28:33] \"POST /uploadText HTTP/1.1\" 500 -\n"
     ]
    }
   ],
   "source": [
    "from flask_cors import CORS\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "CORS(app)\n",
    "\n",
    "# Getting Questions upon Input\n",
    "\n",
    "# Processes\n",
    "def processImage(image):\n",
    "    image = Image.open(image)\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    return text\n",
    "\n",
    "# Getting Questions\n",
    "def getQuestions(text):\n",
    "\n",
    "    chunks = text_splitter.split_text(text)\n",
    "\n",
    "    vectorstore = FAISS.from_texts(texts = chunks , embedding = embeddings)\n",
    "\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(temperature=0, model='gpt-4',openai_api_key='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'),\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        memory=memory\n",
    "    )\n",
    "\n",
    "    query = '''You are an AI assistant that provides a set of 5 questions on the text given to you. \n",
    "    The difficulty level of each question varies, with the first question being easy, the second question being a medium difficulty, the third question being a hard difficulty, the fourth question being a harder difficulty and the fifth question being the hardest difficulty.\n",
    "    You have to generate questions in the format: \n",
    "     -- ['QUESTION1', 'QUESTION2', 'QUESTION3', 'QUESTION4', 'QUESTION5'] --\n",
    "        Please generate questions relevant to the provided text only, in increasing difficulty. Make sure the questions are comma seperated. Just try your best, even if its not completely correct, just generate any possible questions.\n",
    "       Generate questions only in the above format of an array of strings.\n",
    "       '''\n",
    "    \n",
    "    result = conversation_chain({'question':query})\n",
    "\n",
    "    return eval(result['answer'])\n",
    "\n",
    "\n",
    "# Getting rating\n",
    "def get_rating(questions, answers, text):\n",
    "\n",
    "    chunks = text_splitter.split_text(text)\n",
    "\n",
    "    vectorstore = FAISS.from_texts(texts = chunks , embedding = embeddings)\n",
    "\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(temperature=0, model='gpt-4',openai_api_key='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'),\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        memory=memory,\n",
    "    \n",
    "    )\n",
    "\n",
    "\n",
    "    query = f''' You are an AI assistant that will receive a bunch of questions and its corresponding answers. Your task is to check whether the answers are correct or not, and send the user a rating out of 5 for each correct question answered.\n",
    "    If you think that the user has answered incorrect, rate that question 0 else 1.\n",
    "    The questions and answers are : \n",
    "    Questions are : {questions}, Corresponding answers are {answers}.\n",
    "    Keep it simple, and within 3 lines or 100 words.\n",
    "    '''\n",
    "\n",
    "    result = conversation_chain({'question':query})\n",
    "\n",
    "    return result['answer']\n",
    "\n",
    "# Implementing route for images\n",
    "@app.route('/uploadImg', methods=['POST'])\n",
    "def uploadImg():\n",
    "\n",
    "    print('Received Image')\n",
    "\n",
    "    if 'image' not in request.files:\n",
    "        return jsonify({'error': 'No image provided'}), 400\n",
    "\n",
    "    image = request.files['image']\n",
    "\n",
    "    try:\n",
    "        text = processImage(image)\n",
    "\n",
    "        arrayOfQuestions  = getQuestions(text)\n",
    "\n",
    "        return jsonify({'output': text, 'questions': arrayOfQuestions })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "    \n",
    "\n",
    "# Implementing route for generic text \n",
    "@app.route('/uploadText', methods=['POST'])\n",
    "def uploadText():\n",
    "    data = request.json\n",
    "    if 'text' in data:\n",
    "        global text\n",
    "        text = data['text']\n",
    "\n",
    "    arrayOfQuestions  =  getQuestions(text)\n",
    "\n",
    "    return jsonify({'output':text, 'questions': arrayOfQuestions })\n",
    "\n",
    "\n",
    "@app.route('/uploadAnswers', methods=['POST'])\n",
    "def return_rating():\n",
    "    rating = ''\n",
    "    data = request.json\n",
    "    if 'questions' in data and 'answers' in data and 'inptext' in data:\n",
    "        questions = data['questions']\n",
    "        answers = data['answers']\n",
    "\n",
    "\n",
    "        global text\n",
    "        text = data['inptext']\n",
    "        if len(answers) == 0:\n",
    "            rating = 'Please send a post request again, I wasn\\'t able to receive the previous one :| '\n",
    "        else:\n",
    "            rating =  get_rating(questions, answers, text)\n",
    "\n",
    "\n",
    "    return jsonify({'output':rating, 'text':text})\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
